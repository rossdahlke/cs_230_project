---
output:
  pdf_document:
    # citation_package: biblatex
    keep_tex: true
    fig_caption: true
    latex_engine: pdflatex
    template: ../svm-latex-ms.tex
title: "Predicting Opinion Change in Deliberative Groups (Natural Language Processing)"
thanks: "Code and data available at: github.com/rossdahlke/cs_230_project"
author:
- name: Ross Dahlke (rdahlke@stanford.edu)
affiliation: Stanford University
abstract: ""
date: "`r format(Sys.time(), '%B %d, %Y')`"
geometry: margin=1in
fontfamily: mathpazo
fontsize: 11pt
spacing: single
bibliography: ../milestone/bibliography.bib
biblio-style: apsr
---

# 1. Introduction

Deliberative Democracy is when a representative sample of people come together for a short period of time to discuss civic issues. The idea is that through a deliberative process, where people are access to objective information and good conditions to discuss, people can come to conclusions on civic issues that are most representative of what people actually want [cite Fishkin book]. In a time where so much discussion about political and civic issues happens in online information bubbles, Deliberative Democracy offers a chance for people to discuss issues on their merit and the freedom to change their opinions in order to reveal a better representation of public opinion. 

Deliberative Democracy Polling is a technique pioneered by Stanford University Professor Jim Fishkin and the Center for Deliberative Democracy (CDD). A Deliberative Poll is where individuals are polled on their opinions before and after a weekend of small-group deliberation. This method allows researchers to measure the change in people's opinions as a result of the deliberative sessions. 

This project uses the results of surveys and transcripts from the CDD's Deliberative Polls to predict group opinion change based on the transcripts from the groups' deliberative sessions. In talking with members of the CDD, they theorized that computational approaches to predicting opinion change might be difficult because of the narrow focus of each of the deliberative sessions. For example, one whole session might be devoted to discussing water policy. And so, water is the main topic of discussion the entire time. Folks from the CDD have also concluded that participants often don't explicitly say that they have changed their opinion on the topic of the deliberative session, even if they reveal a change in opinion in the survey. Given this prior information, I will work on building a model to predict opinion change in two steps:

  1. (For this milestone) Experimenting with predicting opinion change based on the words and text of the deliberative sessions.
  2. (For the final submission) Experimenting with predicting opinion change by incorporating linguistic features
  
Based on previous discussions with members of the CDC, I will first try to find a baseline model based on the text found in the transcripts. For the final project I will try to incorporate linguistic features into the models. Incorporating linguistic features will be a key component of this project because I hypothesize that it is not _what_ people talk about in the deliberative sessions, it is _how_ they talk about the issues that indicates opinion change. For example, how subjective or objective are the statements people are making in the deliberative setting, or how are sentences structured in groups that show opinion change versus don't show opinion change?
  
# 2. Related work

This project derives its inspiration from two main previous papers: "Attitude Change on Reddit's Change My View" [@cmv] and "A Deep-Learning Approach for Identifying Collective Action Events with Text and Image Data from Social Media" [@zhang]. The former paper found that the "the amount of evidence provided in a discussion predicts attitude change" on the Change My View Reddit forum. The latter paper was able to identify and collective action events in China based on image and text data and provides inspiration on using text data to identify collective behavior that has real-world application and can be a component of future computational social science research. 

# 3. Dataset and Features

This project thanks the CDD for sharing their data. For this project, I have access to surveys and transcripts from three Deliberative Polls, each consisting of about 14 groups, with each group discussing in two or three different sessions. The surveys allow me to calculate opinion change on the issues discussed in each session before and after the deliberations. I use these pre- and post-surveys (responses on a 1-10 scale) to calculate an average delta in opinion change for each deliberative group for each topic session which I use as my dependent variable. The transcripts are broken down by group by session, but they are not attributed to specific individuals. While the additional granularity of individually-attributed transcripts would have great and is something to consider devoting resources to in the future, these group-level opinion deltas and transcripts provide enough data to complete the task. In total, there are 101 examples. I break these down into 71 training examples, 20 validation examples, and 10 test examples. 

# 4. Methods

To capture changes in the differences in the words that disscusants use through their deliberations, I break each transcript down into 1/10th chunks. I then calculated the similarity of each 1/10th chunk to each other by comparing the word embeddings of each chunk [spacy]. For example, of a given transcript, there might be a similarity of .9 between the first and second 1/10th chunks and a similarity of .7 between the third and fourth 1/10th chunks. I use these similarities from each transcript to build two simple OLS models [sklearn]. The first baseline model just uses the similarity of the second and tenth chunks (the first chunk is generally devoted to introductions, welcomes, etc.) to predict opinion deltas. The second model uses all of the similarities to try predict opinion deltas. I also train a basic neural network in Pytorch to try to predict the opinion deltas from all of the similarities. 

In addition to this approach of using word embeddings, I also build a baseline model using Long short-term memory on the sequences of words in the transcripts. 

# 5. Experiments/ Results/ Discussion

# 6. Next Steps

These basic models provide a good baseline estimate of how well one can predict opinion change based on the words that people use in deliberations. My next steps are to incorporate linguistic features. I plan to incorporate the findings of the Priniski and Horne paper that the amount of evidence provided in discussions predicts opinion change. I also examine the preditive ability of polarity and subjectivity of statements in the transcripts. One limitation of this project is the relatively small number of training examples available. And so, I will also leverage transformers to see if they provide the ability to better predict opinion change.

# References
